{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "309b1b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9)\n",
      "(7352,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt', 'r') as file1:\n",
    "    lines1 = file1.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/body_acc_y_train.txt', 'r') as file2:\n",
    "    lines2 = file2.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/body_acc_z_train.txt', 'r') as file3:\n",
    "    lines3 = file3.readlines()\n",
    "    \n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/body_gyro_x_train.txt', 'r') as file4:\n",
    "    lines4 = file4.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/body_gyro_y_train.txt', 'r') as file5:\n",
    "    lines5 = file5.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/body_gyro_z_train.txt', 'r') as file6:\n",
    "    lines6 = file6.readlines()\n",
    "    \n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt', 'r') as file7:\n",
    "    lines7 = file7.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt', 'r') as file8:\n",
    "    lines8 = file8.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt', 'r') as file9:\n",
    "    lines9 = file9.readlines()\n",
    "    \n",
    "with open('./UCI HAR Dataset/train/y_train.txt', 'r') as file10:\n",
    "    lines10 = file10.readlines()\n",
    "    \n",
    "ba_x = [line.strip().split() for line in lines1]\n",
    "ba_y = [line.strip().split() for line in lines2]\n",
    "ba_z = [line.strip().split() for line in lines3]\n",
    "bg_x = [line.strip().split() for line in lines4]\n",
    "bg_y = [line.strip().split() for line in lines5]\n",
    "bg_z = [line.strip().split() for line in lines6]\n",
    "ta_x = [line.strip().split() for line in lines7]\n",
    "ta_y = [line.strip().split() for line in lines8]\n",
    "ta_z = [line.strip().split() for line in lines9]\n",
    "la = [line.strip().split() for line in lines10]\n",
    "\n",
    "x_train = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(ba_x)):\n",
    "    temp = np.vstack((ba_x[i], ba_y[i], ba_z[i], bg_x[i], bg_y[i], bg_z[i], ta_x[i], ta_y[i], ta_z[i]))\n",
    "    x_train.append(temp)\n",
    "    labels.append(la[i][0])\n",
    "\n",
    "x_train = np.dstack(x_train)\n",
    "\n",
    "# Transpose the array\n",
    "x_train = np.transpose(x_train, (2, 1, 0))\n",
    "\n",
    "y_train = np.asarray(labels)\n",
    "\n",
    "print(x_train.shape)  # Output: (7352, 128, 4)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cf26d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 128, 9)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt', 'r') as file1:\n",
    "    lines1 = file1.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt', 'r') as file2:\n",
    "    lines2 = file2.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt', 'r') as file3:\n",
    "    lines3 = file3.readlines()\n",
    "    \n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt', 'r') as file4:\n",
    "    lines4 = file4.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt', 'r') as file5:\n",
    "    lines5 = file5.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt', 'r') as file6:\n",
    "    lines6 = file6.readlines()\n",
    "    \n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt', 'r') as file7:\n",
    "    lines7 = file7.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt', 'r') as file8:\n",
    "    lines8 = file8.readlines()\n",
    "\n",
    "with open('./UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt', 'r') as file9:\n",
    "    lines9 = file9.readlines()\n",
    "    \n",
    "with open('./UCI HAR Dataset/test/y_test.txt', 'r') as file10:\n",
    "    lines10 = file10.readlines()\n",
    "    \n",
    "ba_x_t = [line.strip().split() for line in lines1]\n",
    "ba_y_t = [line.strip().split() for line in lines2]\n",
    "ba_z_t = [line.strip().split() for line in lines3]\n",
    "bg_x_t = [line.strip().split() for line in lines4]\n",
    "bg_y_t = [line.strip().split() for line in lines5]\n",
    "bg_z_t = [line.strip().split() for line in lines6]\n",
    "ta_x_t = [line.strip().split() for line in lines7]\n",
    "ta_y_t = [line.strip().split() for line in lines8]\n",
    "ta_z_t = [line.strip().split() for line in lines9]\n",
    "la_t = [line.strip().split() for line in lines10]\n",
    "\n",
    "x_test = []\n",
    "labels_t = []\n",
    "\n",
    "for i in range(len(ba_x_t)):\n",
    "    temp_t = np.vstack((ba_x_t[i], ba_y_t[i], ba_z_t[i], bg_x_t[i], bg_y_t[i], bg_z_t[i], ta_x_t[i], ta_y_t[i], ta_z_t[i]))\n",
    "    x_test.append(temp_t)\n",
    "    labels_t.append(la_t[i][0])\n",
    "\n",
    "x_test = np.dstack(x_test)\n",
    "\n",
    "# Transpose the array\n",
    "x_test = np.transpose(x_test, (2, 1, 0))\n",
    "\n",
    "y_test = np.asarray(labels_t)\n",
    "\n",
    "print(x_test.shape)  # Output: (7352, 128, 4)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47453f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "x_train = x_train.astype(float)\n",
    "x_test = x_test.astype(float)\n",
    "\n",
    "y_train.astype(int)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 2, 64, 9))\n",
    "x_test = x_test.reshape((x_test.shape[0], 2, 64, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a8c4cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3782\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_119 (TimeD  (None, None, 62, 64)     1792      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_120 (TimeD  (None, None, 31, 64)     0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_121 (TimeD  (None, None, 29, 128)    24704     \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_122 (TimeD  (None, None, 14, 128)    0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_123 (TimeD  (None, None, 1792)       0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " lstm_3777 (LSTM)            (None, 100)               757200    \n",
      "                                                                 \n",
      " dense_1730 (Dense)          (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_1731 (Dense)          (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1732 (Dense)          (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 799,383\n",
      "Trainable params: 799,383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 23:12:38.005294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-25 23:12:38.005858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-25 23:12:38.006418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, Dropout, MaxPooling1D, Flatten, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None, 64,9)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Conv1D(filters=128, kernel_size=3, activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70421030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 23:12:40.313776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-25 23:12:40.314438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-25 23:12:40.315134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-25 23:12:40.531299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-25 23:12:40.531838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-25 23:12:40.532636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 45ms/step - loss: 1.4004 - accuracy: 0.4774\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.5722 - accuracy: 0.7557\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.4248 - accuracy: 0.8225\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.3105 - accuracy: 0.8758\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.2195 - accuracy: 0.9170\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.1667 - accuracy: 0.9374\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.1406 - accuracy: 0.9441\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.1275 - accuracy: 0.9474\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.1164 - accuracy: 0.9497\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1186 - accuracy: 0.9479\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.1169 - accuracy: 0.9510\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.1078 - accuracy: 0.9528\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.0998 - accuracy: 0.9551\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0973 - accuracy: 0.9561\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0949 - accuracy: 0.9576\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0925 - accuracy: 0.9587\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0972 - accuracy: 0.9553\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0956 - accuracy: 0.9576\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0963 - accuracy: 0.9551\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.0898 - accuracy: 0.9595\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0865 - accuracy: 0.9597\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.0937 - accuracy: 0.9548\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.0908 - accuracy: 0.9587\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.0843 - accuracy: 0.9589\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0841 - accuracy: 0.9614\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0846 - accuracy: 0.9580\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.2633 - accuracy: 0.9144\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.1966 - accuracy: 0.9255\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 0.1042 - accuracy: 0.9527\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 0.0837 - accuracy: 0.9627\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x33518a8e0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x33518a8e0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x33518a8e0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x33518a8e0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x33518a8e0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x33518a8e0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 1/93 [..............................] - ETA: 19s - loss: 0.0750 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 23:13:01.173393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-25 23:13:01.173894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-25 23:13:01.174377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9203\n",
      "Test Loss: 0.2882968783378601\n",
      "Test Accuracy: 0.9202578663825989\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train, y_train, X_test, y_test are your training and test datasets\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=500)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085e3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
